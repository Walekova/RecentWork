## “All models are wrong” – What do we do about it?

Machine learning will continue to transform every aspect of our lives; the way we interact with each other, the way we learn and develop, and the way we interact with the society. These services will inadvertently break every so often.      	

*... all models are approximations. Essentially, all models are wrong, but some are useful.* – George E.P. Box 

In other words; no model, machine learning or artificial intelligence solution can be right at all times. If we agree that the failures cannot be avoided, then our main concern is to focus on the processes and controls that can effectively and efficiently minimise any adverse impact on individuals. 

The machine learning governance framework has to cover solutions from idea inception to solution decommissioning, and needs to:
1.      Prevent solution problems by design
2.  	Rectify any issues in an expedited, transparent and responsible manner
3.      Improve the governance framework continuously 

### Prevent 
The effort to minimise adverse impacts starts with an internal assurance process that a provided solution adheres to the principles of fairness. 

The definition of fairness, however, poses a number of challenges. Not only do individuals have a different perception of what is fair but there is also a greater variety of views across geography. There is a need to establish professional bodies that will actively develop a unified vision. With appropriate definition and clarity of what constitutes a fair solution – ‘fairness’ may be a core element of the machine learning solution design. And instead of embedding our own bias, if we incorporate ‘Diversity by design’, we may find the ultimate impact of machine learning to be positive. 

Every principle or rule that a professional body or internal governance framework may stipulate is still, however, subject to individual interpretation. Segregation of duties and a formal compliance process with these principles is the key to success.
       	
#### Rectify 
As we are unable to completely eliminate adverse impacts with the prevention by design, it is important that the process to rectify any failures in a transparent and expedited way is defined and it is core to any product or service deployment. 

*ART* - accountability, responsibility and transparency should be a core component of organisation culture and translated into objectives of all individuals involved in the development and maintenance of machine learning solutions. Raising any ethical issues related to any internal or external application of machine learning should be encouraged and provide similar protection as whistleblowing does. 

In fact, the responsibility to raise ethical concerns should not only reside with internal but also with external stakeholders, i.e. customers, suppliers, government, etc. Both the organisations who develop machine learning solutions as well as the professional body need to enable all stakeholders to raise their concerns. 

The process could be similar to the GDPR process, where individuals have the right to request information from companies to understand what personal information they hold. The organisations in turn are obliged to respond to such requests within a month. This period is sufficient to carry out an ‘ethical principle’ assessment and enable the organisation to prevent any further adverse impact on individuals. 

### Improve 
Machine learning applications as well as the society will continue to evolve. As a result, the fairness definition and governance framework will need to evolve simultaneously. All organisations should therefore allow for flexibility to enable a continuous review and improvement. 
