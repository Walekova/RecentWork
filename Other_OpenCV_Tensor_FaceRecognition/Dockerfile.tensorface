# This builds the tensorrt docker file 
# docker build -t tensorface -f Dockerfile.tensorface .
# to run this container, do:
# on the host:
# make sure you're in the X environment
# xhost + 
# docker run --rm --privileged -p 8888:8888 -e DISPLAY -v /tmp:/tmp -ti tensorface bash
# mount mybucket 
# chmod 777 store.sh
# .\ store.sh

FROM w251/keras:dev-tx2-4.2.1_b97-py3

RUN apt update && apt install python3-matplotlib python3-pil wget -y

###### install the c++ version of protobuf ####
RUN pip3 uninstall -y protobuf
RUN pip3 install cython
RUN apt install -y python3-opencv vim libopencv-dev
RUN pip3 install Pillow

RUN mkdir /protobuf
WORKDIR /protobuf
RUN git clone -b '3.6.x' https://github.com/google/protobuf.git . && \
    ./autogen.sh && \
    ./configure --prefix=/usr/local 

RUN make -j6 && make install
RUN ldconfig

WORKDIR /protobuf/python
RUN python3 setup.py build --cpp_implementation
RUN python3 setup.py install --cpp_implementation
RUN rm -fr /protobuf

WORKDIR /notebooks
###########
RUN git clone --recursive https://github.com/NVIDIA-Jetson/tf_trt_models.git
WORKDIR tf_trt_models
RUN ./install.sh python3

WORKDIR /

COPY tensor.py .
COPY store.sh .
COPY frozen_inference_graph_face.pb .

CMD python tensor.py
